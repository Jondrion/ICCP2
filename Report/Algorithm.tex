\subsection*{Rosenbluth Algorithm}

The most basic method to simulate a SAW is that of simple sampling which goes as follows: place a first segment at the origin and a second one at unit distance. Choose a random angle to place the next segment at unit distance from the previous segment and check the self-avoidance. If the chain is self-avoiding, the growth process continues until the desired length is reached. If not, the polymer is discarded and we start again from scratch. The completed SAW's are independent of each other and occur with the same probability but this probability gets exponentially small for increasing length $N$. This problem of very low efficiency is called the attrition problem.

The Rosenbluth algorithm (also called RR) aims to solve this attrition problem by not putting the next bead in the chain at random but by scanning the environment for neighbouring beads and only choosing those directions which lead to self-avoidance. It is clear that the attrition is strongly reduced but also a bias is introduced. A SAW is no longer produced with uniform probability, but with probability inversely proportional to the number of open directions:

\begin{equation} \label{eq:prob_RR}
	P\!\left(\mathbf{x}\right) = \prod_{i=1}^{N} \frac{1}{n_i} .
\end{equation}
Here $n_i$ is the number of open directions for adding bead number $i$ and $\mathbf{x}$ is the position vector of all the beads in the polymer.

Polymers that have a smaller $n_i$ have thus a higher probability of being generated and this method therefore has a bias towards dense configurations. This bias can be corrected for by incorporating the weight $W\!\left( \mathbf{x} \right) \propto 1/ P\!\left( \mathbf{x} \right)$ when calculating observables.

The bias towards dense configurations also means that the RR method is not useful for long SAW's. Only a small number of polymers generated by the RR method will have large end-to-end distance (and large weight). This portion of large polymers becomes smaller with increased number of beads $N$. The RR method has to be repeated a great number of times to sample long SAW's and is therefore not suitable. The broad distribution of weights leads to a large variance of the calculated observables. In the next section this problem will be solved.

\subsection*{Pruning and Enriching (PERM)}
A more modern algorithm is the Pruned-Enriched Rosenbluth Method or PERM. The main idea of PERM is to keep the distribution of weights within certain bounds by killing polymers with a small weight and cloning polymers with a large weight.

Suppose that a polymer chain is created up to bead number $i$ using the RR method and has a weight $W_i$. In order to prevent this $W_i$ from fluctuating, the sample should be either ``pruned" or ``enriched" when this weight becomes too small or too large respectively. This is done in the following way:

\begin{itemize}
  \item If $W_i$ becomes too small (i.e. $W_i < \textup{LowLim}$) the polymer is destroyed with a probability of 50\%. If the polymer is not destroyed, its weight is doubled and the growth continues.
  \item If $W_i$ becomes too large (i.e. $W_i > \textup{UpLim}$) the polymer is cloned and its weight is halved. The growth now continues for both polymers.
\end{itemize}

Important is to note that no choice of LowLim and UpLim can render the algorithm incorrect. This is because the pruning and enriching does not introduce a bias. The increase of $W_i$ by pruning is compensated by the probability of 50\% that the polymer is not destroyed. The decrease of $W_i$ by enriching is compensated by making a copy. Therefore bad choices of upper and lower limit can only make the algorithm inefficient but not incorrect.

One way of getting good choices for the upper and lower limit is by updating them according to previously obtained weights. This is done by calculating the average weight at each step $i$ of the algorithm: $\left \langle W_i \right \rangle$. This average is updated for every polymer reaching the length $i$. Now the bounds are calculated according to:

\begin{equation} \label{eq:LowLim_UpLim}
\begin{aligned}
	\textup{LowLim} &= \alpha_- \left \langle W_i \right \rangle / \left \langle W_3 \right \rangle \\
	\textup{UpLim} &= \alpha_+ \left \langle W_i \right \rangle / \left \langle W_3 \right \rangle
\end{aligned}
\end{equation}
Choise of $\alpha_-$ and $\alpha_+$ will determine whether the population grows, shrinks or remains constant.

\subsection*{Rosenbluth and dilute polymer solutions}
One last important thing to note is that the methods described so far all use uniform probability for choosing from the available angles when placing a next bead. This is not a good simulation of a polymer in a solution because in that case there should be an inter-monomer potential and the angles should be chosen with a probability proportional to the corresponding polymer energy.
Therefore a routine is used in which the possible angles of a new bead are discretised and for each of these discrete angles the interaction energy with the existing polymer chain is calculated. These energies $E\!\left(\theta_j\right)$ are used to calculate the weights:

\begin{equation}
	w_j^{(i)} = \exp [-E\left(\theta_j\right) / \left( k_B T \right)]
\end{equation}
and their sum $W^{(i)} = \sum_j w_j^{(i)}$. Now every angle $\theta_j$ gets chosen with probability $w_j^{(i)}/W^{(i)}$. This implies that the weight of the polymer is:

\begin{equation}
	W\!(\mathbf{x}) = \exp\left[-E_{total}/ \left( k_B T \right) \right] = \prod_{i=3}^{N} w_j^{(i)}
\end{equation}